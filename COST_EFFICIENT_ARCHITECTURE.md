# AI Application Architecture for Cost Efficiency

## Overview

This document outlines architectural patterns and designs for building cost-efficient AI applications that minimize unnecessary LLM usage while maximizing functionality.

---

## Core Architecture Principle

**ğŸ¯ LLMs are expensive last-resort tools, not first-choice solutions.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Request Pipeline                        â”‚
â”‚                                                             â”‚
â”‚  1. Deterministic Logic (FREE)                             â”‚
â”‚         â†“                                                   â”‚
â”‚  2. Rule-Based Systems (FREE)                              â”‚
â”‚         â†“                                                   â”‚
â”‚  3. Cache Lookup (CHEAP)                                   â”‚
â”‚         â†“                                                   â”‚
â”‚  4. Cheap Model (Haiku/GPT-3.5)                           â”‚
â”‚         â†“                                                   â”‚
â”‚  5. Expensive Model (Sonnet/Opus) - ONLY IF NECESSARY     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Layered Decision Architecture

### Layer 0: Input Validation (Deterministic)

**Cost: $0.00 | Speed: Microseconds**

```python
class InputValidator:
    """Always validate before touching LLM"""

    def validate(self, input_data):
        # Length checks
        if len(input_data) > MAX_LENGTH:
            return ValidationError("Input too long")

        # Format validation
        if not self.is_valid_format(input_data):
            return ValidationError("Invalid format")

        # Content filtering
        if self.contains_banned_content(input_data):
            return ValidationError("Inappropriate content")

        # Language detection (using library)
        if detect_language(input_data) not in SUPPORTED_LANGUAGES:
            return ValidationError("Unsupported language")

        return ValidationSuccess()

# âŒ BAD: Send everything to LLM
response = llm.call("Validate this input: " + user_input)

# âœ… GOOD: Validate first, LLM only if needed
validation = validator.validate(user_input)
if not validation.is_valid():
    return validation.error
# Only now consider LLM if needed
```

### Layer 1: Rule-Based Logic (Deterministic)

**Cost: $0.00 | Speed: Milliseconds**

```python
class IntentRouter:
    """Route requests using rules before LLM"""

    def route(self, message: str):
        # Keyword matching
        if any(word in message.lower() for word in ['price', 'cost', 'how much']):
            return self.handle_pricing_query()

        # Regex patterns
        if re.match(r'^\d{10}$', message):  # Phone number
            return self.handle_phone_lookup()

        # Command detection
        if message.startswith('/'):
            return self.handle_command(message)

        # FAQ matching
        faq_match = self.fuzzy_match_faq(message)
        if faq_match and faq_match.confidence > 0.9:
            return faq_match.answer

        # Only use LLM for complex queries
        return self.llm_intent_classification(message)
```

### Layer 2: Cache Layer

**Cost: ~$0.00 | Speed: Milliseconds**

```python
class SmartCache:
    """Multi-level caching strategy"""

    def __init__(self):
        self.exact_cache = {}      # Exact match
        self.semantic_cache = {}   # Similar queries
        self.response_cache = {}   # Response templates

    def get(self, query: str):
        # Level 1: Exact match
        if query in self.exact_cache:
            return self.exact_cache[query]

        # Level 2: Semantic similarity (using embeddings)
        similar = self.find_similar(query, threshold=0.95)
        if similar:
            return self.semantic_cache[similar]

        # Level 3: Template match
        template = self.match_template(query)
        if template:
            return self.fill_template(template, query)

        return None  # Cache miss - proceed to LLM
```

### Layer 3: Model Selection Layer

**Cost: Varies | Speed: Seconds**

```python
class ModelRouter:
    """Choose cheapest model capable of handling task"""

    TASK_COMPLEXITY = {
        'extract_email': 1,        # Regex can do this
        'sentiment': 2,            # Haiku
        'summarize': 3,            # Haiku/Sonnet
        'reasoning': 4,            # Sonnet
        'creative_writing': 5,     # Sonnet/Opus
        'complex_analysis': 6,     # Opus
    }

    def route(self, task_type: str, content: str):
        complexity = self.TASK_COMPLEXITY.get(task_type, 3)

        # Try deterministic first
        if complexity == 1:
            return self.deterministic_handler(content)

        # Use cheap model for simple tasks
        if complexity <= 3:
            response = self.haiku.call(content)
            # Fallback to better model if confidence is low
            if response.confidence < 0.8:
                return self.sonnet.call(content)
            return response

        # Complex tasks - use expensive model
        return self.opus.call(content)
```

---

## 2. Component Architecture

### A. Request Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User Request                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pre-Processing Layer (Deterministic)                       â”‚
â”‚  â€¢ Input sanitization                                       â”‚
â”‚  â€¢ Format validation                                        â”‚
â”‚  â€¢ Language detection                                       â”‚
â”‚  â€¢ Length normalization                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Rule Engine (Deterministic)                                â”‚
â”‚  â€¢ Keyword matching                                         â”‚
â”‚  â€¢ Regex patterns                                           â”‚
â”‚  â€¢ FAQ lookup                                               â”‚
â”‚  â€¢ Command routing                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
              Can Handle? â”€â”€â”€YESâ”€â”€â†’ Return Response
                     â”‚
                     NO
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cache Layer                                                â”‚
â”‚  â€¢ Exact match cache                                        â”‚
â”‚  â€¢ Semantic similarity cache                                â”‚
â”‚  â€¢ Response template cache                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
              Cache Hit? â”€â”€â”€YESâ”€â”€â†’ Return Cached Response
                     â”‚
                     NO
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Router                                               â”‚
â”‚  â€¢ Classify task complexity                                 â”‚
â”‚  â€¢ Select cheapest capable model                            â”‚
â”‚  â€¢ Apply rate limiting                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Execution                                              â”‚
â”‚  â€¢ Token counting                                           â”‚
â”‚  â€¢ API call with timeout                                    â”‚
â”‚  â€¢ Response validation                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Post-Processing                                            â”‚
â”‚  â€¢ Cache response                                           â”‚
â”‚  â€¢ Log token usage                                          â”‚
â”‚  â€¢ Update metrics                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### B. System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway Layer                         â”‚
â”‚  â€¢ Rate limiting per user/tier                              â”‚
â”‚  â€¢ Request validation                                        â”‚
â”‚  â€¢ Authentication/Authorization                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Application Service Layer                       â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Rule Engine     â”‚  â”‚ Cache Serviceâ”‚  â”‚ Model Router   â”‚ â”‚
â”‚  â”‚ (Deterministic) â”‚  â”‚              â”‚  â”‚                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM Abstraction Layer                           â”‚
â”‚  â€¢ Provider-agnostic interface                              â”‚
â”‚  â€¢ Fallback logic                                           â”‚
â”‚  â€¢ Token counting                                           â”‚
â”‚  â€¢ Cost tracking                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              External LLM Providers                          â”‚
â”‚  [ Anthropic ]  [ OpenAI ]  [ Others ]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Observability Layer (Cross-cutting)             â”‚
â”‚  â€¢ Token usage metrics                                       â”‚
â”‚  â€¢ Cost tracking per endpoint                                â”‚
â”‚  â€¢ Performance monitoring                                    â”‚
â”‚  â€¢ Alert system                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Deterministic Logic Examples

### Example 1: Email Extraction

```python
# âŒ EXPENSIVE: Using LLM
def extract_email_expensive(text: str):
    prompt = f"Extract the email address from this text: {text}"
    response = llm.call(prompt)  # Cost: ~$0.001 per request
    return response

# âœ… CHEAP: Using regex
def extract_email_cheap(text: str):
    pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(pattern, text)
    return emails[0] if emails else None  # Cost: $0.00
```

**Savings:** 100% cost reduction, 1000x faster

### Example 2: Date Parsing

```python
# âŒ EXPENSIVE: Using LLM
def parse_date_expensive(date_string: str):
    prompt = f"Parse this date and return ISO format: {date_string}"
    response = llm.call(prompt)
    return response

# âœ… CHEAP: Using dateutil
from dateutil import parser

def parse_date_cheap(date_string: str):
    try:
        dt = parser.parse(date_string)
        return dt.isoformat()
    except ValueError:
        return None  # Or use LLM only for ambiguous cases
```

**Savings:** 100% cost reduction, instant response

### Example 3: Sentiment Analysis

```python
# âŒ EXPENSIVE: Always using LLM
def sentiment_expensive(text: str):
    prompt = f"Classify sentiment: {text}"
    return llm.call(prompt)  # Cost: $0.001-0.01 per request

# âœ… SMART: Hybrid approach
from textblob import TextBlob

def sentiment_smart(text: str):
    # Use free library for clear cases
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity

    # Clear positive
    if polarity > 0.5:
        return {"sentiment": "positive", "confidence": 0.95}
    # Clear negative
    elif polarity < -0.5:
        return {"sentiment": "negative", "confidence": 0.95}
    # Unclear - use LLM
    else:
        return llm.classify_sentiment(text)
```

**Savings:** 70-80% cost reduction (most cases handled by free library)

### Example 4: Language Detection

```python
# âŒ EXPENSIVE: Using LLM
def detect_language_expensive(text: str):
    prompt = f"What language is this: {text}"
    return llm.call(prompt)

# âœ… CHEAP: Using langdetect
from langdetect import detect

def detect_language_cheap(text: str):
    try:
        return detect(text)  # Cost: $0.00, accuracy: 95%+
    except:
        return 'unknown'
```

**Savings:** 100% cost reduction

### Example 5: Data Validation

```python
# âŒ EXPENSIVE: Using LLM
def validate_phone_expensive(phone: str):
    prompt = f"Is this a valid phone number: {phone}"
    return llm.call(prompt)

# âœ… CHEAP: Using regex and phonenumbers library
import phonenumbers

def validate_phone_cheap(phone: str, region: str = 'US'):
    try:
        parsed = phonenumbers.parse(phone, region)
        return phonenumbers.is_valid_number(parsed)
    except:
        return False
```

**Savings:** 100% cost reduction

### Example 6: Simple Classification

```python
# âŒ EXPENSIVE: Using LLM for everything
def classify_ticket_expensive(ticket: str):
    prompt = f"Classify this support ticket: {ticket}"
    return llm.call(prompt)

# âœ… CHEAP: Keywords + rules first, LLM for edge cases
def classify_ticket_smart(ticket: str):
    ticket_lower = ticket.lower()

    # Rule-based classification (handles 80% of cases)
    keywords = {
        'billing': ['invoice', 'payment', 'charge', 'refund', 'price'],
        'technical': ['error', 'bug', 'crash', 'not working', 'broken'],
        'account': ['login', 'password', 'reset', 'access', 'locked'],
    }

    for category, words in keywords.items():
        if any(word in ticket_lower for word in words):
            return {
                'category': category,
                'confidence': 0.9,
                'method': 'rule-based'
            }

    # LLM for complex/ambiguous cases (20%)
    return llm.classify(ticket)
```

**Savings:** 80% cost reduction

### Example 7: Text Normalization

```python
# âŒ EXPENSIVE: Using LLM
def normalize_text_expensive(text: str):
    prompt = f"Normalize and clean this text: {text}"
    return llm.call(prompt)

# âœ… CHEAP: String operations
def normalize_text_cheap(text: str):
    # Remove extra whitespace
    text = ' '.join(text.split())
    # Convert to lowercase
    text = text.lower()
    # Remove special characters
    text = re.sub(r'[^\w\s]', '', text)
    # Trim
    text = text.strip()
    return text
```

**Savings:** 100% cost reduction

---

## 4. Decision Matrix: When to Use LLM

| Task Type | Use Deterministic | Use LLM | Justification |
|-----------|------------------|---------|---------------|
| Email extraction | âœ… | âŒ | Regex is 100% accurate and free |
| Date parsing | âœ… | âŒ | Libraries handle all formats |
| URL validation | âœ… | âŒ | Regex/validators work perfectly |
| Phone validation | âœ… | âŒ | phonenumbers library is comprehensive |
| Language detection | âœ… | âŒ | langdetect is 95%+ accurate |
| Simple math | âœ… | âŒ | eval() or math library |
| Sentiment (clear) | âœ… | âŒ | TextBlob/VADER for obvious cases |
| Sentiment (nuanced) | âŒ | âœ… | Sarcasm, context needs LLM |
| Intent (keywords) | âœ… | âŒ | Pattern matching sufficient |
| Intent (complex) | âŒ | âœ… | Natural language understanding |
| Translation | âŒ | âœ… | Quality matters |
| Summarization | âŒ | âœ… | Requires understanding |
| Creative writing | âŒ | âœ… | Human-like output needed |
| Code generation | âŒ | âœ… | Complex logic required |

---

## 5. Architecture Patterns

### Pattern 1: Cascade Pattern

```python
class CascadeProcessor:
    """Try cheap methods first, cascade to expensive"""

    def process(self, input_data):
        # Level 1: Free
        result = self.try_deterministic(input_data)
        if result.confidence > 0.95:
            return result

        # Level 2: Cheap
        result = self.try_haiku(input_data)
        if result.confidence > 0.90:
            return result

        # Level 3: Expensive
        return self.try_opus(input_data)
```

### Pattern 2: Hybrid Pattern

```python
class HybridProcessor:
    """Combine deterministic + LLM"""

    def process(self, input_data):
        # Step 1: Extract structured data (free)
        structured = self.extract_deterministic(input_data)

        # Step 2: Only send unstructured parts to LLM
        if structured.has_ambiguous_parts():
            structured.ambiguous = self.llm_process(
                structured.ambiguous_parts
            )

        return structured
```

### Pattern 3: Preprocessing Pattern

```python
class PreprocessingPipeline:
    """Reduce LLM input size with deterministic preprocessing"""

    def process(self, document: str):
        # Step 1: Extract relevant sections (free)
        relevant = self.extract_relevant_sections(document)

        # Step 2: Remove boilerplate (free)
        cleaned = self.remove_boilerplate(relevant)

        # Step 3: Chunk intelligently (free)
        chunks = self.smart_chunking(cleaned)

        # Step 4: Only process most relevant chunk with LLM
        most_relevant = self.rank_chunks(chunks)[0]
        return self.llm_process(most_relevant)  # Reduced tokens
```

---

## 6. Cost-Aware Design Checklist

### Before Writing Code

- [ ] Can this be solved with regex?
- [ ] Can this be solved with a library?
- [ ] Can this be solved with simple logic?
- [ ] Is there a rule-based approach?
- [ ] Can I cache the results?
- [ ] What's the simplest model that works?

### During Implementation

- [ ] Added input validation (deterministic)
- [ ] Implemented caching layer
- [ ] Set max_tokens limits
- [ ] Added token usage logging
- [ ] Implemented rate limiting
- [ ] Added confidence-based fallback
- [ ] Error handling with retries

### After Implementation

- [ ] Measured token usage
- [ ] Calculated cost per request
- [ ] Identified optimization opportunities
- [ ] Set up monitoring alerts
- [ ] Documented why LLM is necessary

---

## 7. Anti-Patterns to Avoid

### âŒ Anti-Pattern 1: LLM for Everything

```python
# BAD: Using LLM for simple tasks
def is_email_valid(email):
    return llm.call(f"Is {email} valid?")  # $0.001

def format_date(date):
    return llm.call(f"Format {date} as ISO")  # $0.001

def uppercase(text):
    return llm.call(f"Convert to uppercase: {text}")  # $0.001
```

**Cost:** $3.00 per 1000 requests
**Fix:** Use built-in string/regex/libraries â†’ $0.00

### âŒ Anti-Pattern 2: No Caching

```python
# BAD: Calling LLM every time
def get_category(product):
    return llm.classify(product)  # Same products = repeated calls
```

**Fix:**
```python
# GOOD: Cache results
@cache(ttl=3600)
def get_category(product):
    return llm.classify(product)
```

### âŒ Anti-Pattern 3: Unbounded Context

```python
# BAD: Sending entire conversation history
def chat(message, history):
    full_context = "\n".join(history) + message  # Grows forever
    return llm.call(full_context)
```

**Fix:**
```python
# GOOD: Limit context window
def chat(message, history):
    recent = history[-10:]  # Only last 10 messages
    context = "\n".join(recent) + message
    return llm.call(context)
```

---

## 8. Reference Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Load Balancer                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Gateway                           â”‚
â”‚  â€¢ Rate Limiting: 100 req/min per user                 â”‚
â”‚  â€¢ Auth: JWT tokens                                     â”‚
â”‚  â€¢ Input Validation: Length, format                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rule Engine      â”‚   â”‚  Redis Cache     â”‚
â”‚ (Deterministic)  â”‚â†â†’â”‚  TTL: 1 hour     â”‚
â”‚ â€¢ Regex          â”‚   â”‚  Hit Rate: 70%   â”‚
â”‚ â€¢ Keywords       â”‚   â”‚                  â”‚
â”‚ â€¢ FAQ Match      â”‚   â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Can Handle?
         â”‚
    YES  â”‚  NO
    â†“    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return â”‚  â”‚   Model Router               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”œâ”€â†’ Haiku (70% of cases)   â”‚
            â”‚   â”œâ”€â†’ Sonnet (25% of cases)  â”‚
            â”‚   â””â”€â†’ Opus (5% of cases)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   LLM Provider Pool        â”‚
            â”‚   â€¢ Anthropic              â”‚
            â”‚   â€¢ OpenAI (fallback)      â”‚
            â”‚   â€¢ Timeout: 30s           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Observability            â”‚
            â”‚   â€¢ Prometheus metrics     â”‚
            â”‚   â€¢ Token usage logs       â”‚
            â”‚   â€¢ Cost per endpoint      â”‚
            â”‚   â€¢ Alert on budget 80%    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Implementation Roadmap

### Phase 1: Foundation (Week 1)
- [ ] Set up input validation layer
- [ ] Implement basic rule engine
- [ ] Add response caching (Redis/in-memory)
- [ ] Set up token usage logging

### Phase 2: Optimization (Week 2-3)
- [ ] Build model router
- [ ] Implement cascade pattern
- [ ] Add semantic similarity cache
- [ ] Set up monitoring dashboard

### Phase 3: Intelligence (Week 4)
- [ ] Add confidence-based fallback
- [ ] Implement smart context pruning
- [ ] Build cost prediction model
- [ ] Add A/B testing framework

### Phase 4: Scale (Ongoing)
- [ ] Optimize based on metrics
- [ ] Expand rule coverage
- [ ] Fine-tune cache TTLs
- [ ] Continuous cost optimization

---

## 10. Success Metrics

### Cost Efficiency
- **Target:** 70%+ requests handled without LLM
- **Target:** Average cost per request < $0.001
- **Target:** 50%+ cost reduction vs naive implementation

### Performance
- **Target:** p95 latency < 500ms for deterministic
- **Target:** p95 latency < 3s for LLM calls
- **Target:** Cache hit rate > 60%

### Quality
- **Target:** Accuracy > 95% for all methods
- **Target:** User satisfaction > 4.5/5
- **Target:** Error rate < 1%

---

**Version:** 1.0
**Last Updated:** February 8, 2026
**Status:** Active
